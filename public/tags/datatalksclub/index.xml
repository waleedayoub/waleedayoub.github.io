<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Datatalksclub on Waleed Ayoub</title>
    <link>http://localhost:1313/tags/datatalksclub/</link>
    <description>Recent content in Datatalksclub on Waleed Ayoub</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Aug 2024 14:50:46 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/datatalksclub/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM Zoomcamp Week 4 - Monitoring and Evaluation Notes</title>
      <link>http://localhost:1313/post/llmzoomcamp_week4-monitoring-evaluation_notes/</link>
      <pubDate>Tue, 06 Aug 2024 14:50:46 -0400</pubDate>
      <guid>http://localhost:1313/post/llmzoomcamp_week4-monitoring-evaluation_notes/</guid>
      <description>&lt;h1 id=&#34;llm-zoomcamp---week-4-notes&#34;&gt;LLM Zoomcamp - Week 4 Notes &lt;!-- omit from toc --&gt;&lt;/h1&gt;&#xA;&lt;p&gt;In this section the focus is on the following:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Extending the evaluation work we did in section 3 to monitor answer quality over time&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to look at answer quality with user feedback and interaction&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;How to store all this data and visualize it, etc.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;But before all that, let&amp;rsquo;s do a quick recap of where we are.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents &lt;!-- omit from toc --&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#recap&#34;&gt;Recap&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#41-intro&#34;&gt;4.1 Intro&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#42-differences-between-online-and-offline-evaluation-with-rags&#34;&gt;4.2 Differences Between Online and Offline Evaluation (with RAGs)&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#techniques-for-offline-evaluation&#34;&gt;Techniques For Offline Evaluation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#43-offline-evaluation-for-our-rag-system&#34;&gt;4.3 Offline Evaluation for our RAG System&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#load-our-faq-documents-with-document-ids&#34;&gt;Load our FAQ Documents with Document IDs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#load-ground-truth-dataset-we-create-using-llms&#34;&gt;Load ground truth dataset we create using LLMs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cosine-similarity-metric&#34;&gt;Cosine Similarity metric&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#evaluating-gpt-35-turbo-vs-gpt-4o-mini&#34;&gt;Evaluating GPT-3.5-turbo vs GPT-4o-mini&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#44-offline-rag-evaluation---cosine-similarity&#34;&gt;4.4 Offline RAG Evaluation - Cosine Similarity&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#45-offline-rag-evaluation---llm-as-a-judge&#34;&gt;4.5 Offline RAG Evaluation - LLM as a Judge&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#46-capturing-user-feedback&#34;&gt;4.6 Capturing User Feedback&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#47-monitoring-the-system&#34;&gt;4.7 Monitoring the System&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;recap&#34;&gt;Recap&lt;/h2&gt;&#xA;&lt;p&gt;A quick recap of what the first three sections have been about:&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Zoomcamp Week 3 - Vector Search with Elasticsearch Notes</title>
      <link>http://localhost:1313/post/llmzoomcamp_week3-vector-search_notes/</link>
      <pubDate>Fri, 19 Jul 2024 15:16:18 -0400</pubDate>
      <guid>http://localhost:1313/post/llmzoomcamp_week3-vector-search_notes/</guid>
      <description>&lt;h1 id=&#34;llm-zoomcamp---week-3-notes&#34;&gt;LLM Zoomcamp - Week 3 Notes &lt;!-- omit from toc --&gt;&lt;/h1&gt;&#xA;&lt;p&gt;In this section the focus is on the following:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Applying Vector Databases as an alternative to Elasticsearch in the previous two models.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Important to note that Elasticsearch has the ability to operate as a Vector DB as an alternative to Lucene and will be covered as well&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Vector embeddings and their role in building RAG applications&lt;/li&gt;&#xA;&lt;li&gt;Evaluation methods for search / query retrieval performance&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents &lt;!-- omit from toc --&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#31-introduction-to-vector-search&#34;&gt;3.1 Introduction to Vector Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#32-how-to-do-vectorized-search-with-elasticsearch&#34;&gt;3.2 How to do Vectorized Search with Elasticsearch&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#321-lets-start-with-semantic-search&#34;&gt;3.2.1 Let&amp;rsquo;s start with Semantic Search&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#step-1---load-our-documents&#34;&gt;Step 1 - Load our documents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#step-2---create-embeddings-using-pre-trained-models&#34;&gt;Step 2 - Create embeddings using pre-trained models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#step-3---set-up-elasticsearch-connection&#34;&gt;Step 3 - Set up Elasticsearch connection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#step-4-create-elasticsearch-mappings-and-index&#34;&gt;Step 4 Create Elasticsearch mappings and index&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#step-5-add-documents-to-the-index&#34;&gt;Step 5 Add documents to the index&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#step-6-create-the-user-query&#34;&gt;Step 6 Create the user query&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#step-7-perform-a-semantic-search-using-elasticsearch-vectordb&#34;&gt;Step 7 Perform a semantic search using Elasticsearch VectorDB&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#322-now-lets-try-advanced-semantic-search&#34;&gt;3.2.2 Now let&amp;rsquo;s try Advanced Semantic Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#33-evaluation&#34;&gt;3.3 Evaluation&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#331-evaluation-metrics-for-retrieval&#34;&gt;3.3.1 Evaluation metrics for retrieval&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#332-ground-truth-generation-for-retrieval-evaluation&#34;&gt;3.3.2 Ground truth generation for retrieval evaluation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#333-evaluation-of-text-retrieval-techniques-for-rag&#34;&gt;3.3.3 Evaluation of text retrieval techniques for RAG&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#334-evaluation-vector-retrieval&#34;&gt;3.3.4 Evaluation vector retrieval&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;31-introduction-to-vector-search&#34;&gt;3.1 Introduction to Vector Search&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Vector search has been around for a while and is getting popular again largely because LLMs lack long-term memory and have limited context windows&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Vector DBs are an economical and effective way to store data for use with LLMs&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Elastic.co does a good job of explaining what vector embeddings are &lt;a href=&#34;https://www.elastic.co/what-is/vector-embedding&#34;&gt;here&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Here&amp;rsquo;s their definition:&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Vector embeddings are a way to convert words and sentences and other data into numbers that capture their meaning and relationships. They represent different data types as points in a multidimensional space, where similar data points are clustered closer together. These numerical representations help machines understand and process this data more effectively.&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Vector databases are databases that index and store vector embeddings&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Which means you can easily store them, reference them, compare different vectors semantically (using various distance measures, etc.)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Here&amp;rsquo;s what it would look like when put together with an LLM:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div style=&#34;max-width: 100%; overflow: hidden;&#34;&gt;&#xA;    &lt;img src=&#34;http://localhost:1313/images/sbert.png&#34; alt=&#34;List of SBERT original models&#34; style=&#34;width: 100%; height: auto;&#34;&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;32-how-to-do-vectorized-search-with-elasticsearch&#34;&gt;3.2 How to do Vectorized Search with Elasticsearch&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Let&amp;rsquo;s start with the architecture of the Semantic Search system we&amp;rsquo;re going to build:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;mermaid-wrapper&#34;&gt;&#xA;    &lt;pre class=&#34;mermaid&#34;&gt;graph LR&#xA;    documents.json --&gt;|load| documents&#xA;    subgraph Process&#xA;        documents --&gt; embeddings&#xA;        embeddings --&gt; index&#xA;        index --&gt;|store| Elasticsearch[(Elasticsearch vector DB)]&#xA;    end&#xA;    Elasticsearch --&gt;|retrieve| Semantic_search_results(Semantic search results)&#xA;    new_search_query(New search query) -.-&gt; embeddings&#xA;    embeddings  -.-&gt; Elasticsearch&#xA;&#x9;&#xA;&#x9;style new_search_query stroke:blue,stroke-width:2px;&#xA;    &lt;/pre&gt;&#xA;&lt;/div&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;The way this system works is as follows:&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Zoomcamp Week 2 - Open Source LLMs Notes</title>
      <link>http://localhost:1313/post/llmzoomcamp_week2-open-source_notes/</link>
      <pubDate>Wed, 10 Jul 2024 16:56:37 -0400</pubDate>
      <guid>http://localhost:1313/post/llmzoomcamp_week2-open-source_notes/</guid>
      <description>&lt;h1 id=&#34;llm-zoomcamp---week-2-notes&#34;&gt;LLM Zoomcamp - Week 2 Notes&lt;/h1&gt;&#xA;&lt;p&gt;In the second week, we set up cloud-based GPU options like SaturnCloud and explore open source alternatives to OpenAI platforms and  models like:&#xA;Platforms:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;HuggingFace&lt;/li&gt;&#xA;&lt;li&gt;Ollama&lt;/li&gt;&#xA;&lt;li&gt;SaturnCloud&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Models:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Google FLAN T5&lt;/li&gt;&#xA;&lt;li&gt;Phi 3 Mini&lt;/li&gt;&#xA;&lt;li&gt;Mistral 7-B&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;And finally, we put the RAG we built in week 1 into a Streamlit UI&lt;/p&gt;&#xA;&lt;p&gt;A few important call outs for this section:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For the most part, I will be taking these notes in a Saturn Cloud notebook&lt;/li&gt;&#xA;&lt;li&gt;Which means that before starting each note section, I will be restarting the kernel to free up RAM from the GPU I&amp;rsquo;m using&lt;/li&gt;&#xA;&lt;li&gt;So if I ever decide to revisit these notes in the future, I won&amp;rsquo;t be able to just load this notebook and run things as is&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#22-using-saturncloud-for-gpu-notebooks&#34;&gt;2.2 Using SaturnCloud for GPU Notebooks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#23-huggingface-and-google-flan-t5&#34;&gt;2.3 HuggingFace and Google FLAN T5&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#24-phi-3-mini&#34;&gt;2.4 Phi 3 Mini&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#25-mistral-7b-and-huggingface-hub-authentication&#34;&gt;2.5 Mistral-7B and HuggingFace Hub Authentication&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#26-exploring-open-source-llms&#34;&gt;2.6 Exploring Open Source LLMs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#27-running-llms-locally-without-a-gpu-with-ollama&#34;&gt;2.7 Running LLMs Locally without a GPU with Ollama&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#28-ollama--elastic-in-docker-compose&#34;&gt;2.8 Ollama + Elastic in Docker Compose&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#docker-compose-setup&#34;&gt;Docker Compose Setup&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#setting-up-elasticsearch-and-ollama&#34;&gt;Setting Up Elasticsearch and Ollama&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#building-the-rag-system&#34;&gt;Building the RAG System&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#29-creating-a-streamlit-ui&#34;&gt;2.9 Creating a Streamlit UI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#bonus-ollama--openwebui--elastic-in-docker-with-gpu&#34;&gt;Bonus Ollama + OpenWebUI + Elastic in Docker with GPU&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; os&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; requests&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;22-using-saturncloud-for-gpu-notebooks&#34;&gt;2.2 Using SaturnCloud for GPU Notebooks&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The main thing not covered is how to give Saturn Cloud access to your GitHub repositories&#xA;&lt;ul&gt;&#xA;&lt;li&gt;This is fairly straightforward:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;In Saturn Cloud, go to &amp;ldquo;Manage &lt;username&gt;&amp;rdquo; and create an SSH key pair&lt;/li&gt;&#xA;&lt;li&gt;Copy the public key Saturn Cloud generates and go to Github.com&#xA;i. In Github.com, go to Settings -&amp;gt; SSH and GPG keys and click on &lt;code&gt;New SSH Key&lt;/code&gt;&#xA;ii. Paste in the public key you copied from Saturn Cloud&lt;/li&gt;&#xA;&lt;li&gt;Now go back to Saturn Cloud and click on &lt;code&gt;Git Repositories&lt;/code&gt;&#xA;i. Click on &lt;code&gt;New&lt;/code&gt;&#xA;ii. Add the url for the Github repository you want Saturn Cloud to have access to&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;When creating a new Python VM resource, make sure to install additional libs: &lt;code&gt;pip install -U transformers accelerate bitsandbytes&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;The rest of it is quite straightforward&lt;/li&gt;&#xA;&lt;li&gt;A few things I did with my setup of the notebook resource that just helps with development:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;I enabled SSH access so that I can ideally connect to this notebook resource in VS Code (and thus take advantange of many things including Github Copilot)&lt;/li&gt;&#xA;&lt;li&gt;I gave the VM an easy to remember name: &lt;a href=&#34;https://llm-zoomcamp-waleed.community.saturnenterprise.io&#34;&gt;https://llm-zoomcamp-waleed.community.saturnenterprise.io&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;I created an access token on huggingface.co and added it as an environment variable on Saturn Cloud (more on that in section 2.5)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;23-huggingface-and-google-flan-t5&#34;&gt;2.3 HuggingFace and Google FLAN T5&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;In this lesson, we start working with open source models available on &lt;a href=&#34;huggingface.co&#34;&gt;HuggingFace&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;HuggingFace is a place where people host models, not just LLMs, all kinds of ML models (which effectively boils down to hosting model weights)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;This is where our Saturn Cloud GPU notebook in 2.2 comes into play as we&amp;rsquo;ll need a GPU to work with these models&lt;/li&gt;&#xA;&lt;li&gt;We&amp;rsquo;re going to be using Google FLAN T5: &lt;a href=&#34;https://huggingface.co/google/flan-t5-xl&#34;&gt;https://huggingface.co/google/flan-t5-xl&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s start by pulling in the minsearch engine we&amp;rsquo;re going to use in our RAG&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Zoomcamp Week 1 - Intro Notes</title>
      <link>http://localhost:1313/post/llmzoomcamp_week1-intro_notes/</link>
      <pubDate>Sat, 29 Jun 2024 08:11:46 -0400</pubDate>
      <guid>http://localhost:1313/post/llmzoomcamp_week1-intro_notes/</guid>
      <description>&lt;h1 id=&#34;llm-zoomcamp---week-1-notes&#34;&gt;LLM Zoomcamp - Week 1 Notes&lt;/h1&gt;&#xA;&lt;p&gt;This is the first week of the new &lt;a href=&#34;https://github.com/DataTalksClub/llm-zoomcamp/tree/main&#34;&gt;LLM Zoomcamp&lt;/a&gt; hosted by &lt;a href=&#34;https://datatalks.club/&#34;&gt;DataTalksClub&lt;/a&gt;.&#xA;I&amp;rsquo;ve found their content really helpful in the past, having completed the Data Engineering Zoomcamp a year ago and successively attempted (but never finished!) the other two zoomcamps they offer.&lt;/p&gt;&#xA;&lt;p&gt;In order to give me the best chance of completing this one, I&amp;rsquo;ve decided to publish my notes on my blog. Hope that helps me see this one through!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Learning to Use Dlthub with Toronto Bicycle Data</title>
      <link>http://localhost:1313/post/learning-to-use-dlthub/</link>
      <pubDate>Mon, 12 Feb 2024 07:56:52 -0500</pubDate>
      <guid>http://localhost:1313/post/learning-to-use-dlthub/</guid>
      <description>&lt;h2 id=&#34;outline&#34;&gt;Outline&lt;/h2&gt;&#xA;&lt;h3 id=&#34;quick-intro-to-what-is-dlthub&#34;&gt;Quick intro to what is dlthub&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Start with the notebook from the data eng zoomcamp as an intro&lt;/li&gt;&#xA;&lt;li&gt;Work through it and take notes as you&amp;rsquo;re going through each section&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;using-toronto-bicycle-data-live-stream-json-using-dictionaries-and-lists&#34;&gt;Using toronto bicycle data live stream json using dictionaries and lists&lt;/h3&gt;&#xA;&lt;h3 id=&#34;doing-the-same-using-dlthub&#34;&gt;Doing the same using dlthub&lt;/h3&gt;</description>
    </item>
    <item>
      <title>Prefect.io POC - Building ETL Pipeline for Toronto Bicycle Data</title>
      <link>http://localhost:1313/post/toronto-bicycle-data/</link>
      <pubDate>Wed, 03 Jan 2024 09:40:43 -0500</pubDate>
      <guid>http://localhost:1313/post/toronto-bicycle-data/</guid>
      <description>&lt;h1 id=&#34;toronto-bicycle-data-engineering&#34;&gt;Toronto Bicycle Data Engineering&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You can find all the code for this project here: &lt;a href=&#34;https://github.com/waleedayoub/toronto-bicycle-data&#34;&gt;https://github.com/waleedayoub/toronto-bicycle-data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;This was a project I explored as part of the &lt;a href=&#34;https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_7_project/README.md&#34;&gt;final project&lt;/a&gt; of the datatalks club data engineering zoomcamp&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;project-description&#34;&gt;Project Description&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The goal of this project is to examine historical bike share ridership going as far back as 2016 in the city of Toronto, Ontario.&lt;/li&gt;&#xA;&lt;li&gt;The city of Toronto has an open data sharing mandate, and all bike share data can be found here: &lt;a href=&#34;https://open.toronto.ca/dataset/bike-share-toronto/&#34;&gt;https://open.toronto.ca/dataset/bike-share-toronto/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Unfortunately, the data is not consistently named or labeled across years (2014-2022, inclusively), so there is a need to perform quite a bit of processing to handle it.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For example, in some years, data is stored in tabs in XLSX files, whereas in other years, they are CSVs broken down by quarters, or in other cases, by months, in CSV files&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Given that this analysis focuses on historical ridership, a batch processing pipeline is sufficient, and can be scheduled to run monthly or quarterly.&lt;/li&gt;&#xA;&lt;li&gt;It is unclear how often the data refreshes, but the following program handles edge cases and checks whether data has been updated before triggering pipelines&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The architecture for this project is kept fairly simple:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div style=&#34;max-width: 100%; overflow: hidden;&#34;&gt;&#xA;    &lt;img src=&#34;http://localhost:1313/images/bikedataarch.png&#34; alt=&#34;Data arch for toronto bicycle data&#34; style=&#34;width: 100%; height: auto;&#34;&gt;&#xA;&lt;/div&gt;&#xA;&lt;h2 id=&#34;data-sources&#34;&gt;Data sources&lt;/h2&gt;&#xA;&lt;h3 id=&#34;toronto&#34;&gt;Toronto&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Ridership data: &lt;a href=&#34;https://open.toronto.ca/dataset/bike-share-toronto-ridership-data/&#34;&gt;https://open.toronto.ca/dataset/bike-share-toronto-ridership-data/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;For batch data, here&amp;rsquo;s an example of how to access the ridership data API:&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;base_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://ckan0.cf.opendata.inter.prod-toronto.ca&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;package_url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; base_url &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/api/3/action/package_show&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;params &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bike-share-toronto-ridership-data&amp;#34;&lt;/span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;&#xA;&lt;li&gt;If you do a GET request on the package_url with params provided like this:&#xA;&lt;code&gt;resource = requests.get(url, params=params).json()&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You can then grab the url where the data is stored like this:&#xA;&lt;code&gt;resource[&amp;quot;result&amp;quot;][&amp;quot;resources&amp;quot;][&amp;quot;url&amp;quot;]&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;And the url will be something like this:&#xA;&lt;a href=&#34;https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/7e876c24-177c-4605-9cef-e50dd74c617f/resource/85326868-508c-497e-b139-b698aaf27bbf/download/bikeshare-ridership-2014-2015.xlsx&#34;&gt;https://ckan0.cf.opendata.inter.prod-toronto.ca/dataset/7e876c24-177c-4605-9cef-e50dd74c617f/resource/85326868-508c-497e-b139-b698aaf27bbf/download/bikeshare-ridership-2014-2015.xlsx&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;You can then do another GET request on that URL and write to a file in Python&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;deployment-instructions&#34;&gt;Deployment instructions&lt;/h2&gt;&#xA;&lt;h3 id=&#34;technologies-used&#34;&gt;Technologies used&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GCP / Cloud Storage / BigQuery / Looker&lt;/li&gt;&#xA;&lt;li&gt;Terraform&lt;/li&gt;&#xA;&lt;li&gt;Prefect / DBT&lt;/li&gt;&#xA;&lt;li&gt;Python 3.9.16 / virtualenv&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;things-you-need-to-install--versions&#34;&gt;Things you need to install + versions&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Google cloud SDK: &lt;a href=&#34;https://cloud.google.com/sdk/docs/install&#34;&gt;https://cloud.google.com/sdk/docs/install&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Terraform 1.4.5: &lt;a href=&#34;https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli&#34;&gt;https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Python: make sure you&amp;rsquo;re running 3.9.16&lt;/li&gt;&#xA;&lt;li&gt;Prefect 2.10.4: &lt;a href=&#34;https://docs.prefect.io/latest/getting-started/installation/&#34;&gt;https://docs.prefect.io/latest/getting-started/installation/&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It is &lt;em&gt;very&lt;/em&gt; important to get the prefect version right as GCS block&amp;rsquo;s &lt;code&gt;upload_from_dataframe()&lt;/code&gt; &lt;a href=&#34;https://prefecthq.github.io/prefect-gcp/cloud_storage/#prefect_gcp.cloud_storage.GcsBucket.upload_from_dataframe&#34;&gt;method&lt;/a&gt; doesn&amp;rsquo;t work in older versions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;step-0&#34;&gt;Step 0&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Clone or copy this repo: &lt;code&gt;git clone git@github.com:waleedayoub/toronto-bicycle-data.git&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;step-1---initial-setup--gcp&#34;&gt;Step 1 - Initial Setup + GCP&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Create a service account in GCP and download the service account json (In the IAM &amp;amp; Admin section of the GCP console)&lt;/p&gt;</description>
    </item>
    <item>
      <title>ML Zoomcamp Week 5 Homework Using Poetry and Pyenv</title>
      <link>http://localhost:1313/post/mlzoomcamp-week5-homework-poetry/</link>
      <pubDate>Mon, 16 Oct 2023 19:08:29 -0400</pubDate>
      <guid>http://localhost:1313/post/mlzoomcamp-week5-homework-poetry/</guid>
      <description>&lt;p&gt;In order to do week5 homework, you need to use pipenv to manage python packages and dependencies&lt;/p&gt;&#xA;&lt;p&gt;An alternative toolset would be to use poetry with pyenv&lt;/p&gt;&#xA;&lt;p&gt;In this case, you would split the management of python applications from python versions:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;poetry would be used to manage packages, dependencies and ensure project reproducibility&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Whereas pyenv would be used to manage python versions&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Install both&lt;/p&gt;&#xA;&lt;p&gt;In your homework directory, you can run poetry init to initialize a poetry project&lt;/p&gt;</description>
    </item>
    <item>
      <title>Git set up for datatalksclub zoomcamp</title>
      <link>http://localhost:1313/post/git-setup-datatalksclub/</link>
      <pubDate>Tue, 05 Sep 2023 22:40:29 -0400</pubDate>
      <guid>http://localhost:1313/post/git-setup-datatalksclub/</guid>
      <description>&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Original course repo as read-only that gets updated throughout the duration of the course&lt;/li&gt;&#xA;&lt;li&gt;My own repo in my github account that is used to get updates from original course repo and for me to write my own assignments / work&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;solution&#34;&gt;Solution&lt;/h2&gt;&#xA;&lt;p&gt;What I&amp;rsquo;m looking to do is essentially maintain a fork of the original course repository, while also adding your own work to it. Here&amp;rsquo;s a step-by-step guide to help you set this up:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
